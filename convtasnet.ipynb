{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "#matplotlib ipympl\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.axes._axes import Axes\n",
    "\n",
    "from IPython.display import Audio\n",
    "# Audio(data=signal.T,rate=fe)\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import stft,istft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=6><b>Meta paramètres</b></font>\n",
    "\n",
    "Comme calculer les spectrogrammes prend du temps, nous pouvons les calculer une fois pour toute puis les sauvegarder sur le disque. Toutefois, <font color=\"red\"><b>ceci triple l'espace occupé sur disque</b></font>: passant de 6.3 Go à 17.2 Go. Veuillez donc préciser le paramètre `SAVE_SPECTROGRAMS` selon si vous pouvez utiliser cet espace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = Path(\"source_separation\")\n",
    "SAVE_SPECTROGRAMS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des signaux, Visualisation et Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des signaux et spectrogrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = DIRECTORY / \"train\"\n",
    "train_small_folder = DIRECTORY / \"train_small\"\n",
    "test_folder = DIRECTORY / \"test\"\n",
    "get_path = lambda folder,i : folder / (\"000\"+str(i))[-4:]\n",
    "\n",
    "datasets_sizes = {\n",
    "    train_small_folder : 50,\n",
    "    train_folder : 5000,\n",
    "    test_folder : 2000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les signaux ont la même fréquence d'échantillonage, même longueur; et donc les mêmes f et t échantillonés pour le Spectrogramme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all_same(folder=train_small_folder):\n",
    "    f_ref = None\n",
    "    t_ref = None\n",
    "    for i in range(datasets_sizes[train_small_folder]):\n",
    "        fe,signal = wavfile.read(get_path(train_small_folder,i) / \"voice.wav\")\n",
    "        len_signal = len(signal)\n",
    "        f_spec,t_spec,spec = stft(\n",
    "            signal,fs=fe,\n",
    "            nperseg=400,nfft=512,noverlap=100)\n",
    "        if f_ref is None: f_ref = f_spec ; t_ref = t_spec\n",
    "        assert np.allclose(f_spec,f_ref)\n",
    "        assert np.allclose(t_spec,t_ref)\n",
    "    return fe,f_ref,t_ref\n",
    "\n",
    "fe,f_ref,t_ref = check_all_same()\n",
    "get_spectrogram = lambda signal : stft(signal,fs=fe,nperseg=400,nfft=512,noverlap=100)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_signal_folder(folder: Path,\n",
    "        load_signals=True,\n",
    "        load_spectrograms=True) -> dict[str,dict]:\n",
    "    \"\"\"\n",
    "    Return a dictionary with 3 sub dicts: \"voice\", \"noise\" and \"mix\"; and an \"SNR\" key.\n",
    "    Each sub dict has 3 keys: \"filename\", \"signal\" and \"spectrogram\" \n",
    "    (except if load_signals or load_spectrograms are set to False)\n",
    "    \"\"\"\n",
    "    keys = [\"voice\",\"noise\",\"mix\"]\n",
    "    res = dict((k,dict()) for k in keys)\n",
    "    for f in folder.iterdir():\n",
    "        assert f.is_file()\n",
    "        if \"voice\" in f.name: key = \"voice\"\n",
    "        elif \"noise\" in f.name: key = \"noise\"\n",
    "        else: \n",
    "            key = \"mix\"\n",
    "            if f.suffix == \".wav\":\n",
    "                res[\"SNR\"] = f.name.removesuffix(\".wav\").split(\"_\")[-1]\n",
    "        if f.suffix == \".wav\" and load_signals:\n",
    "            fe,signal = wavfile.read(f)\n",
    "            res[key][\"filename\"] = f.name\n",
    "            res[key][\"signal\"] = signal\n",
    "        elif f.suffix == \".pt\" and SAVE_SPECTROGRAMS and load_spectrograms: \n",
    "            # when SAVE_SPECTROGRAMS is False, we shouldn't be able to load them \n",
    "            # to save time, otherwise it's cheating.\n",
    "            res[key][\"spectrogram\"] = torch.load(f,weights_only=True)\n",
    "    # Create missing spectrograms\n",
    "    if load_spectrograms:\n",
    "        for key in keys:\n",
    "            if \"spectrogram\" not in res[key]:\n",
    "                assert load_signals\n",
    "                spec = get_spectrogram(res[key][\"signal\"])\n",
    "                res[key][\"spectrogram\"] = spec\n",
    "                if SAVE_SPECTROGRAMS:\n",
    "                    torch.save(torch.tensor(spec),folder / f\"{key}_spectrogram.pt\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def remove_all_spectrograms():\n",
    "    for folder in [train_folder,train_small_folder,test_folder]:\n",
    "        for i in range(datasets_sizes[folder]):\n",
    "            folder_i: Path = get_path(folder,i)\n",
    "            for f in folder_i.iterdir():\n",
    "                if \"spectrogram\" in f.name:\n",
    "                    f.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme calculer les spectrogrammes prend du temps, nous pouvons les calculer une fois pour toute, en sauvegardant tous les spectrogrammes sur disque. Attention, <font color=\"red\"><b>ceci triple l'espace occupé sur disque</b></font>: passant de 6.3 Go à 17.2 Go.\n",
    "Pour les retirer utiliser: `remove_all_spectrograms()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrograms(folder: Path):\n",
    "    if SAVE_SPECTROGRAMS and not (folder/\"0000\"/\"voice_spectrogram.pt\").exists():\n",
    "        for i in range(datasets_sizes[folder]):\n",
    "            load_signal_folder(get_path(folder,i))\n",
    "\n",
    "create_spectrograms(train_small_folder)\n",
    "create_spectrograms(test_folder)\n",
    "create_spectrograms(train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Première fois:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'weights_only' is an invalid keyword argument for Unpickler()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComparé au temps pour charger les spectrogrammes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_load_spec\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPremière fois:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mcompute_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDeuxième fois:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m compute_time(test_folder)\n",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m, in \u001b[0;36mcompute_time\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      9\u001b[0m path_spec: Path \u001b[38;5;241m=\u001b[39m get_path(folder,i) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoice_spectrogram.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path_spec\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m---> 11\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m time_load_spec \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start ; start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     13\u001b[0m _ \u001b[38;5;241m=\u001b[39m get_spectrogram(signal)\n",
      "File \u001b[0;32m~/.conda/envs/torch_env/lib/python3.10/site-packages/torch/serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/.conda/envs/torch_env/lib/python3.10/site-packages/torch/serialization.py:1047\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;66;03m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m data_file \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(zip_file\u001b[38;5;241m.\u001b[39mget_record(pickle_file))\n\u001b[0;32m-> 1047\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m \u001b[43mUnpicklerWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m   1049\u001b[0m result \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'weights_only' is an invalid keyword argument for Unpickler()"
     ]
    }
   ],
   "source": [
    "def compute_time(folder):\n",
    "    time_load_signal = 0\n",
    "    time_load_spec = 0\n",
    "    time_spec = 0\n",
    "    start = time.perf_counter()\n",
    "    for i in range(datasets_sizes[folder]):\n",
    "        fe,signal = wavfile.read(get_path(folder,i) / \"voice.wav\")\n",
    "        time_load_signal += time.perf_counter() - start ; start = time.perf_counter()\n",
    "        path_spec: Path = get_path(folder,i) / \"voice_spectrogram.pt\"\n",
    "        if path_spec.exists():\n",
    "            _ = torch.load(path_spec,weights_only=True)\n",
    "        time_load_spec += time.perf_counter() - start ; start = time.perf_counter()\n",
    "        _ = get_spectrogram(signal)\n",
    "        time_spec += time.perf_counter() - start ; start = time.perf_counter()\n",
    "\n",
    "    print(f\"Temps total pour load {datasets_sizes[folder]} signaux: {time_load_signal}\")\n",
    "    print(f\"Temps total pour en calculer les spectrogrammes: {time_spec}\")\n",
    "    print(f\"Comparé au temps pour charger les spectrogrammes: {time_load_spec}\")\n",
    "\n",
    "print(\"Première fois:\")\n",
    "compute_time(test_folder)\n",
    "print(\"\\nDeuxième fois:\")\n",
    "compute_time(test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que charger les spectrogrammes pré-calculés est plus rapide que de les calculer à chaque fois. On note aussi une grosse différence entre la première fois qu'un fichier est chargé et la seconde, j'imagine que le système place les derniers fichiers chargés dans le cache (recharger le notebook n'y change rien, donc la différence n'apparait que la toute première fois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">Note: les versions très récentes de `ipympl` ont une erreur de frappe dans le code, avec une variable nommé \"buttons\" au lieu de \"button\". Ainsi, si vous avez une version instable de `ipympl`, il se peut que d'un coup la cellule interactive ci-dessous écrivent des dizaines d'erreurs à la chaine. Nous n'avons pas trouvé ce qui les déclenche, mais vous pouvez les ignorer (puisqu'elles n'empechent pas la cellule de tourner), sinon vous pouvez simplement ouvrir le fichier d'où vient l'erreur (en cliquant sur la ligne d'erreur qui s'affiche des dizaines de fois), et changé \"buttons\", par \"button\".</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x250 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4772222da4f04049a7bb3cd61208c919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='i', max=49), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_signal(folder):\n",
    "    signals = load_signal_folder(folder)\n",
    "    colorbars = []\n",
    "    for ax,name in zip(axs,[\"voice\",\"noise\",\"mix\"]):\n",
    "        spec_dB = 10*np.log10(abs(signals[name][\"spectrogram\"].numpy()))\n",
    "        plt_obj = ax.pcolormesh(\n",
    "            t_ref,f_ref,spec_dB,\n",
    "            vmax=np.percentile(spec_dB,99),\n",
    "            vmin=np.percentile(spec_dB,10))\n",
    "        colorbars.append(plt.colorbar(plt_obj,ax=ax))\n",
    "        ax.set_title(signals[name][\"filename\"])\n",
    "        ax.tick_params(axis='both', which='major', labelsize=4)\n",
    "        colorbars[-1].ax.tick_params(axis='both', which='major', labelsize=4)\n",
    "        ax.set_xlabel(\"Temps (ms)\",fontsize=4)\n",
    "        ax.set_ylabel(\"Fréquence (GHz)\",fontsize=4)\n",
    "    return colorbars\n",
    "\n",
    "\n",
    "folder = train_small_folder\n",
    "plt.close(\"viz\")\n",
    "fig_viz = plt.figure(\"viz\",figsize=(7,2.5))\n",
    "gs = gridspec.GridSpec(2,3) # to get good control of the color bars\n",
    "ax_slices = [np.s_[:,i] for i in range(3)]\n",
    "axs = [fig_viz.add_subplot(gs[sli]) for sli in ax_slices]\n",
    "colorbars = []\n",
    "\n",
    "@widgets.interact(i=(0,datasets_sizes[folder]-1,1))\n",
    "def update(i=1):\n",
    "    for ax in axs: ax.cla()\n",
    "    global colorbars\n",
    "    fig_viz = plt.figure(\"viz\")\n",
    "    plt.title(\"\")\n",
    "    try: \n",
    "        if colorbars != []:\n",
    "            for colorbar in colorbars:\n",
    "                fig_viz.delaxes(colorbar.ax)\n",
    "            gs = gridspec.GridSpec(2,3)\n",
    "            for ax,sli in zip(axs,ax_slices):\n",
    "                ax.set_position(gs[sli].get_position(fig_viz))\n",
    "                ax.set_subplotspec(gs[sli])\n",
    "    except:\n",
    "        print('got an error')\n",
    "        pass\n",
    "    folder_i = get_path(folder,i)\n",
    "    colorbars = visualize_signal(folder_i)\n",
    "    fig_viz.suptitle(f\"Spectogrammes pour {Path(folder_i.parent.name)/folder_i.name}\")\n",
    "    fig_viz.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "            folder: Path,\n",
    "            load_signals=True,\n",
    "            load_spectrograms=False):\n",
    "        self.folder = folder\n",
    "        self.load_signals = load_signals\n",
    "        self.load_spectrograms = load_spectrograms\n",
    "            \n",
    "    def __len__(self):\n",
    "        return datasets_sizes[self.folder]\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        d = load_signal_folder(\n",
    "            get_path(self.folder,i),\n",
    "            load_signals=self.load_signals,\n",
    "            load_spectrograms=self.load_spectrograms)\n",
    "        ret = []\n",
    "        for name in [\"voice\",\"noise\",\"mix\"]:\n",
    "            if self.load_signals:\n",
    "                ret.append(d[name][\"signal\"])\n",
    "            if self.load_spectrograms:\n",
    "                ret.append(d[name][\"spectrogram\"])\n",
    "        ret.append(d[\"SNR\"])\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Dataset peut contenir les signaux et/ou les spectrogrammes. De sorte à ne charger que le nécessaire. Exemple si on veut tout charger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 5000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'weights_only' is an invalid keyword argument for Unpickler()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset length:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mlen\u001b[39m(train_dataset))\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m voice_signal,voice_spec,noise_signal,noise_spec,mix_signal,mix_spec,snr \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSignal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m,voice_signal\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpectrogram\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m,voice_spec\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.conda/envs/torch_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    677\u001b[0m             data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n\u001b[1;32m    678\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m--> 681\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_MultiProcessingDataLoaderIter\u001b[39;00m(_BaseDataLoaderIter):\n\u001b[1;32m    682\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates once over the DataLoader's dataset, as specified by the sampler.\"\"\"\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;66;03m# NOTE [ Data Loader Multiprocessing Shutdown Logic ]\u001b[39;00m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# Preliminary:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;66;03m#     processing indices already in `index_queue` if we are already shutting\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;66;03m#     down.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m class _MultiProcessingDataLoaderIter(_BaseDataLoaderIter):\n\u001b[1;32m    682\u001b[0m     r\"\"\"Iterates once over the DataLoader's dataset, as specified by the sampler.\"\"\"\n\u001b[1;32m    684\u001b[0m     # NOTE [ Data Loader Multiprocessing Shutdown Logic ]\n\u001b[1;32m    685\u001b[0m     #\n\u001b[1;32m    686\u001b[0m     # Preliminary:\n\u001b[1;32m    687\u001b[0m     #\n\u001b[1;32m    688\u001b[0m     # Our data model looks like this (queues are indicated with curly brackets):\n\u001b[1;32m    689\u001b[0m     #\n\u001b[1;32m    690\u001b[0m     #                main process                              ||\n\u001b[1;32m    691\u001b[0m     #                     |                                    ||\n\u001b[1;32m    692\u001b[0m     #               {index_queue}                              ||\n\u001b[1;32m    693\u001b[0m     #                     |                                    ||\n\u001b[1;32m    694\u001b[0m     #              worker processes                            ||     DATA\n\u001b[1;32m    695\u001b[0m     #                     |                                    ||\n\u001b[1;32m    696\u001b[0m     #            {worker_result_queue}                         ||     FLOW\n\u001b[1;32m    697\u001b[0m     #                     |                                    ||\n\u001b[1;32m    698\u001b[0m     #      pin_memory_thread of main process                   ||   DIRECTION\n\u001b[1;32m    699\u001b[0m     #                     |                                    ||\n\u001b[1;32m    700\u001b[0m     #               {data_queue}                               ||\n\u001b[1;32m    701\u001b[0m     #                     |                                    ||\n\u001b[1;32m    702\u001b[0m     #                data output                               \\/\n\u001b[1;32m    703\u001b[0m     #\n\u001b[1;32m    704\u001b[0m     # P.S. `worker_result_queue` and `pin_memory_thread` part may be omitted if\n\u001b[1;32m    705\u001b[0m     #      `pin_memory=False`.\n\u001b[1;32m    706\u001b[0m     #\n\u001b[1;32m    707\u001b[0m     #\n\u001b[1;32m    708\u001b[0m     # Terminating multiprocessing logic requires very careful design. In\n\u001b[1;32m    709\u001b[0m     # particular, we need to make sure that\n\u001b[1;32m    710\u001b[0m     #\n\u001b[1;32m    711\u001b[0m     #   1. The iterator gracefully exits the workers when its last reference is\n\u001b[1;32m    712\u001b[0m     #      gone or it is depleted.\n\u001b[1;32m    713\u001b[0m     #\n\u001b[1;32m    714\u001b[0m     #      In this case, the workers should be gracefully exited because the\n\u001b[1;32m    715\u001b[0m     #      main process may still need to continue to run, and we want cleaning\n\u001b[1;32m    716\u001b[0m     #      up code in the workers to be executed (e.g., releasing GPU memory).\n\u001b[1;32m    717\u001b[0m     #      Naturally, we implement the shutdown logic in `__del__` of\n\u001b[1;32m    718\u001b[0m     #      DataLoaderIterator.\n\u001b[1;32m    719\u001b[0m     #\n\u001b[1;32m    720\u001b[0m     #      We delay the discussion on the logic in this case until later.\n\u001b[0;32m--> 721\u001b[0m     #\n\u001b[1;32m    722\u001b[0m     #   2. The iterator exits the workers when the loader process and/or worker\n\u001b[1;32m    723\u001b[0m     #      processes exits normally or with error.\n\u001b[1;32m    724\u001b[0m     #\n\u001b[1;32m    725\u001b[0m     #      We set all workers and `pin_memory_thread` to have `daemon=True`.\n\u001b[1;32m    726\u001b[0m     #\n\u001b[1;32m    727\u001b[0m     #      You may ask, why can't we make the workers non-daemonic, and\n\u001b[1;32m    728\u001b[0m     #      gracefully exit using the same logic as we have in `__del__` when the\n\u001b[1;32m    729\u001b[0m     #      iterator gets deleted (see 1 above)?\n\u001b[1;32m    730\u001b[0m     #\n\u001b[1;32m    731\u001b[0m     #      First of all, `__del__` is **not** guaranteed to be called when\n\u001b[1;32m    732\u001b[0m     #      interpreter exits. Even if it is called, by the time it executes,\n\u001b[1;32m    733\u001b[0m     #      many Python core library resources may already be freed, and even\n\u001b[1;32m    734\u001b[0m     #      simple things like acquiring an internal lock of a queue may hang.\n\u001b[1;32m    735\u001b[0m     #      Therefore, in this case, we actually need to prevent `__del__` from\n\u001b[1;32m    736\u001b[0m     #      being executed, and rely on the automatic termination of daemonic\n\u001b[1;32m    737\u001b[0m     #      children.\n\u001b[1;32m    738\u001b[0m     #\n\u001b[1;32m    739\u001b[0m     #      Thus, we register an `atexit` hook that sets a global flag\n\u001b[1;32m    740\u001b[0m     #      `_utils.python_exit_status`. Since `atexit` hooks are executed in the\n\u001b[1;32m    741\u001b[0m     #      reverse order of registration, we are guaranteed that this flag is\n\u001b[1;32m    742\u001b[0m     #      set before library resources we use are freed (which, at least in\n\u001b[1;32m    743\u001b[0m     #      CPython, is done via an `atexit` handler defined in\n\u001b[1;32m    744\u001b[0m     #      `multiprocessing/util.py`\n\u001b[1;32m    745\u001b[0m     #      https://github.com/python/cpython/blob/c606624af8d4cb3b4a052fb263bb983b3f87585b/Lib/multiprocessing/util.py#L320-L362\n\u001b[1;32m    746\u001b[0m     #      registered when an object requiring this mechanism is first\n\u001b[1;32m    747\u001b[0m     #      created, e.g., `mp.Queue`\n\u001b[1;32m    748\u001b[0m     #      https://github.com/python/cpython/blob/c606624af8d4cb3b4a052fb263bb983b3f87585b/Lib/multiprocessing/context.py#L100-L103\n\u001b[1;32m    749\u001b[0m     #      https://github.com/python/cpython/blob/c606624af8d4cb3b4a052fb263bb983b3f87585b/Lib/multiprocessing/queues.py#L29\n\u001b[1;32m    750\u001b[0m     #      )\n\u001b[1;32m    751\u001b[0m     #\n\u001b[1;32m    752\u001b[0m     #      So in `__del__`, we check if `_utils.python_exit_status` is set or\n\u001b[1;32m    753\u001b[0m     #      `None` (freed), and perform no-op if so.\n\u001b[1;32m    754\u001b[0m     #\n\u001b[1;32m    755\u001b[0m     #      However, simply letting library clean-up codes run can also be bad,\n\u001b[1;32m    756\u001b[0m     #      because such codes (i.e., `multiprocessing.util._exit_function()`)\n\u001b[1;32m    757\u001b[0m     #      include join putting threads for `mp.Queue`, which can be blocking.\n\u001b[1;32m    758\u001b[0m     #      Hence, the main process putting threads are called with\n\u001b[1;32m    759\u001b[0m     #      `cancel_join_thread` at creation.  See later section\n\u001b[1;32m    760\u001b[0m     #      [ 3b. A process won't hang when putting into a queue; ]\n\u001b[1;32m    761\u001b[0m     #      for more details.\n\u001b[1;32m    762\u001b[0m     #\n\u001b[1;32m    763\u001b[0m     #      Here are two example cases where library clean-up codes can run\n\u001b[1;32m    764\u001b[0m     #      before `__del__` is called:\n\u001b[1;32m    765\u001b[0m     #\n\u001b[1;32m    766\u001b[0m     #        1. If we hold onto a reference to the iterator, it more often\n\u001b[1;32m    767\u001b[0m     #           than not tries to do `multiprocessing` library cleaning before\n\u001b[1;32m    768\u001b[0m     #           clearing the alive referenced objects (https://github.com/pytorch/pytorch/issues/48666)\n\u001b[1;32m    769\u001b[0m     #           and thus prevents our cleaning-up code to run first.\n\u001b[1;32m    770\u001b[0m     #\n\u001b[1;32m    771\u001b[0m     #        2. A similar issue araises when a `DataLoader` is used in a subprocess.\n\u001b[1;32m    772\u001b[0m     #           When a process ends, it shuts the all its daemonic children\n\u001b[1;32m    773\u001b[0m     #           down with a SIGTERM (instead of joining them without a timeout).\n\u001b[1;32m    774\u001b[0m     #           Simiarly for threads, but by a different mechanism. This fact,\n\u001b[1;32m    775\u001b[0m     #           together with a few implementation details of multiprocessing, forces\n\u001b[1;32m    776\u001b[0m     #           us to make workers daemonic. All of our problems arise when a\n\u001b[1;32m    777\u001b[0m     #           DataLoader is used in a subprocess, and are caused by multiprocessing\n\u001b[1;32m    778\u001b[0m     #           code which looks more or less like this:\n\u001b[1;32m    779\u001b[0m     #\n\u001b[1;32m    780\u001b[0m     #               try:\n\u001b[1;32m    781\u001b[0m     #                   your_function_using_a_dataloader()\n\u001b[1;32m    782\u001b[0m     #               finally:\n\u001b[1;32m    783\u001b[0m     #                   multiprocessing.util._exit_function()\n\u001b[1;32m    784\u001b[0m     #\n\u001b[1;32m    785\u001b[0m     #           The joining/termination mentioned above happens inside\n\u001b[1;32m    786\u001b[0m     #           `_exit_function()`. Now, if `your_function_using_a_dataloader()`\n\u001b[1;32m    787\u001b[0m     #           throws, the stack trace stored in the exception will prevent the\n\u001b[1;32m    788\u001b[0m     #           frame which uses `DataLoaderIter` to be freed. If the frame has any\n\u001b[1;32m    789\u001b[0m     #           reference to the `DataLoaderIter` (e.g., in a method of the iter),\n\u001b[1;32m    790\u001b[0m     #           its  `__del__`, which starts the shutdown procedure, will not be\n\u001b[1;32m    791\u001b[0m     #           called. That, in turn, means that workers aren't notified. Attempting\n\u001b[1;32m    792\u001b[0m     #           to join in `_exit_function` will then result in a hang.\n\u001b[1;32m    793\u001b[0m     #\n\u001b[1;32m    794\u001b[0m     #           For context, `_exit_function` is also registered as an `atexit` call.\n\u001b[1;32m    795\u001b[0m     #           So it is unclear to me (@ssnl) why this is needed in a finally block.\n\u001b[1;32m    796\u001b[0m     #           The code dates back to 2008 and there is no comment on the original\n\u001b[1;32m    797\u001b[0m     #           PEP 371 or patch https://bugs.python.org/issue3050 (containing both\n\u001b[1;32m    798\u001b[0m     #           the finally block and the `atexit` registration) that explains this.\n\u001b[1;32m    799\u001b[0m     #\n\u001b[1;32m    800\u001b[0m     #\n\u001b[1;32m    801\u001b[0m     #      Finally, another choice is to just shutdown workers with logic in 1\n\u001b[1;32m    802\u001b[0m     #      above whenever we see an error in `next`. This isn't ideal because\n\u001b[1;32m    803\u001b[0m     #        a. It prevents users from using try-catch to resume data loading.\n\u001b[1;32m    804\u001b[0m     #        b. It doesn't prevent hanging if users have references to the\n\u001b[1;32m    805\u001b[0m     #           iterator.\n\u001b[1;32m    806\u001b[0m     #\n\u001b[1;32m    807\u001b[0m     #   3. All processes exit if any of them die unexpectedly by fatal signals.\n\u001b[1;32m    808\u001b[0m     #\n\u001b[1;32m    809\u001b[0m     #      As shown above, the workers are set as daemonic children of the main\n\u001b[1;32m    810\u001b[0m     #      process. However, automatic cleaning-up of such child processes only\n\u001b[1;32m    811\u001b[0m     #      happens if the parent process exits gracefully (e.g., not via fatal\n\u001b[1;32m    812\u001b[0m     #      signals like SIGKILL). So we must ensure that each process will exit\n\u001b[1;32m    813\u001b[0m     #      even the process that should send/receive data to/from it were\n\u001b[1;32m    814\u001b[0m     #      killed, i.e.,\n\u001b[1;32m    815\u001b[0m     #\n\u001b[1;32m    816\u001b[0m     #        a. A process won't hang when getting from a queue.\n\u001b[1;32m    817\u001b[0m     #\n\u001b[1;32m    818\u001b[0m     #           Even with carefully designed data dependencies (i.e., a `put()`\n\u001b[1;32m    819\u001b[0m     #           always corresponding to a `get()`), hanging on `get()` can still\n\u001b[1;32m    820\u001b[0m     #           happen when data in queue is corrupted (e.g., due to\n\u001b[1;32m    821\u001b[0m     #           `cancel_join_thread` or unexpected exit).\n\u001b[1;32m    822\u001b[0m     #\n\u001b[1;32m    823\u001b[0m     #           For child exit, we set a timeout whenever we try to get data\n\u001b[1;32m    824\u001b[0m     #           from `data_queue`, and check the workers' status on each timeout\n\u001b[1;32m    825\u001b[0m     #           and error.\n\u001b[1;32m    826\u001b[0m     #           See `_DataLoaderiter._get_batch()` and\n\u001b[1;32m    827\u001b[0m     #           `_DataLoaderiter._try_get_data()` for details.\n\u001b[1;32m    828\u001b[0m     #\n\u001b[1;32m    829\u001b[0m     #           Additionally, for child exit on non-Windows platforms, we also\n\u001b[1;32m    830\u001b[0m     #           register a SIGCHLD handler (which is supported on Windows) on\n\u001b[1;32m    831\u001b[0m     #           the main process, which checks if any of the workers fail in the\n\u001b[1;32m    832\u001b[0m     #           (Python) handler. This is more efficient and faster in detecting\n\u001b[1;32m    833\u001b[0m     #           worker failures, compared to only using the above mechanism.\n\u001b[1;32m    834\u001b[0m     #           See `DataLoader.cpp` and `_utils/signal_handling.py` for details.\n\u001b[1;32m    835\u001b[0m     #\n\u001b[1;32m    836\u001b[0m     #           For `.get()` calls where the sender(s) is not the workers, we\n\u001b[1;32m    837\u001b[0m     #           guard them with timeouts, and check the status of the sender\n\u001b[1;32m    838\u001b[0m     #           when timeout happens:\n\u001b[1;32m    839\u001b[0m     #             + in the workers, the `_utils.worker.ManagerWatchdog` class\n\u001b[1;32m    840\u001b[0m     #               checks the status of the main process.\n\u001b[1;32m    841\u001b[0m     #             + if `pin_memory=True`, when getting from `pin_memory_thread`,\n\u001b[1;32m    842\u001b[0m     #               check `pin_memory_thread` status periodically until `.get()`\n\u001b[1;32m    843\u001b[0m     #               returns or see that `pin_memory_thread` died.\n\u001b[1;32m    844\u001b[0m     #\n\u001b[1;32m    845\u001b[0m     #        b. A process won't hang when putting into a queue;\n\u001b[1;32m    846\u001b[0m     #\n\u001b[1;32m    847\u001b[0m     #           We use `mp.Queue` which has a separate background thread to put\n\u001b[1;32m    848\u001b[0m     #           objects from an unbounded buffer array. The background thread is\n\u001b[1;32m    849\u001b[0m     #           daemonic and usually automatically joined when the process\n\u001b[1;32m    850\u001b[0m     #           *exits*.\n\u001b[1;32m    851\u001b[0m     #\n\u001b[1;32m    852\u001b[0m     #           In case that the receiver has ended abruptly while\n\u001b[1;32m    853\u001b[0m     #           reading from the pipe, the join will hang forever.  The usual\n\u001b[1;32m    854\u001b[0m     #           solution for this in Python is calling  `q.cancel_join_thread`,\n\u001b[1;32m    855\u001b[0m     #           which prevents automatically joining it when finalizing\n\u001b[1;32m    856\u001b[0m     #           (exiting).\n\u001b[1;32m    857\u001b[0m     #\n\u001b[1;32m    858\u001b[0m     #           Nonetheless, `cancel_join_thread` must only be called when the\n\u001b[1;32m    859\u001b[0m     #           queue is **not** going to be read from or write into by another\n\u001b[1;32m    860\u001b[0m     #           process, because it may hold onto a lock or leave corrupted data\n\u001b[1;32m    861\u001b[0m     #           in the queue, leading other readers/writers to hang.\n\u001b[1;32m    862\u001b[0m     #\n\u001b[1;32m    863\u001b[0m     #           Hence,\n\u001b[1;32m    864\u001b[0m     #             + For worker processes, we only do so (for their output\n\u001b[1;32m    865\u001b[0m     #               queues, i.e., `worker_result_queue`) before exiting.\n\u001b[1;32m    866\u001b[0m     #             + For `pin_memory_thread`, its output queue `data_queue` is a\n\u001b[1;32m    867\u001b[0m     #               `queue.Queue` that does blocking `put` if the queue is full.\n\u001b[1;32m    868\u001b[0m     #               So there is no above problem, but as a result, in\n\u001b[1;32m    869\u001b[0m     #               `_pin_memory_loop`, we do need to  wrap the `put` in a loop\n\u001b[1;32m    870\u001b[0m     #               that breaks not only upon success, but also when the main\n\u001b[1;32m    871\u001b[0m     #               process stops reading, i.e., is shutting down.\n\u001b[1;32m    872\u001b[0m     #             + For loader process, we `cancel_join_thread()` for all\n\u001b[1;32m    873\u001b[0m     #               `_index_queues` because the whole purpose of workers and\n\u001b[1;32m    874\u001b[0m     #               `pin_memory_thread` is to serve the loader process.  If\n\u001b[1;32m    875\u001b[0m     #               loader process is already exiting, we don't really care if\n\u001b[1;32m    876\u001b[0m     #               the queues are corrupted.\n\u001b[1;32m    877\u001b[0m     #\n\u001b[1;32m    878\u001b[0m     #\n\u001b[1;32m    879\u001b[0m     # Now let's get back to 1:\n\u001b[1;32m    880\u001b[0m     #   how we gracefully exit the workers when the last reference to the\n\u001b[1;32m    881\u001b[0m     #   iterator is gone.\n\u001b[1;32m    882\u001b[0m     #\n\u001b[1;32m    883\u001b[0m     # To achieve this, we implement the following logic along with the design\n\u001b[1;32m    884\u001b[0m     # choices mentioned above:\n\u001b[1;32m    885\u001b[0m     #\n\u001b[1;32m    886\u001b[0m     # `workers_done_event`:\n\u001b[1;32m    887\u001b[0m     #   A `multiprocessing.Event` shared among the main process and all worker\n\u001b[1;32m    888\u001b[0m     #   processes. This is used to signal the workers that the iterator is\n\u001b[1;32m    889\u001b[0m     #   shutting down. After it is set, they will not send processed data to\n\u001b[1;32m    890\u001b[0m     #   queues anymore, and only wait for the final `None` before exiting.\n\u001b[1;32m    891\u001b[0m     #   `done_event` isn't strictly needed. I.e., we can just check for `None`\n\u001b[1;32m    892\u001b[0m     #   from the input queue, but it allows us to skip wasting resources\n\u001b[1;32m    893\u001b[0m     #   processing data if we are already shutting down.\n\u001b[1;32m    894\u001b[0m     #\n\u001b[1;32m    895\u001b[0m     # `pin_memory_thread_done_event`:\n\u001b[1;32m    896\u001b[0m     #   A `threading.Event` for a similar purpose to that of\n\u001b[1;32m    897\u001b[0m     #   `workers_done_event`, but is for the `pin_memory_thread`. The reason\n\u001b[1;32m    898\u001b[0m     #   that separate events are needed is that `pin_memory_thread` reads from\n\u001b[1;32m    899\u001b[0m     #   the output queue of the workers. But the workers, upon seeing that\n\u001b[1;32m    900\u001b[0m     #   `workers_done_event` is set, only wants to see the final `None`, and is\n\u001b[1;32m    901\u001b[0m     #   not required to flush all data in the output queue (e.g., it may call\n\u001b[1;32m    902\u001b[0m     #   `cancel_join_thread` on that queue if its `IterableDataset` iterator\n\u001b[1;32m    903\u001b[0m     #   happens to exhaust coincidentally, which is out of the control of the\n\u001b[1;32m    904\u001b[0m     #   main process). Thus, since we will exit `pin_memory_thread` before the\n\u001b[1;32m    905\u001b[0m     #   workers (see below), two separete events are used.\n\u001b[1;32m    906\u001b[0m     #\n\u001b[1;32m    907\u001b[0m     # NOTE: In short, the protocol is that the main process will set these\n\u001b[1;32m    908\u001b[0m     #       `done_event`s and then the corresponding processes/threads a `None`,\n\u001b[1;32m    909\u001b[0m     #       and that they may exit at any time after receiving the `None`.\n\u001b[1;32m    910\u001b[0m     #\n\u001b[1;32m    911\u001b[0m     # NOTE: Using `None` as the final signal is valid, since normal data will\n\u001b[1;32m    912\u001b[0m     #       always be a 2-tuple with the 1st element being the index of the data\n\u001b[1;32m    913\u001b[0m     #       transferred (different from dataset index/key), and the 2nd being\n\u001b[1;32m    914\u001b[0m     #       either the dataset key or the data sample (depending on which part\n\u001b[1;32m    915\u001b[0m     #       of the data model the queue is at).\n\u001b[1;32m    916\u001b[0m     #\n\u001b[1;32m    917\u001b[0m     # [ worker processes ]\n\u001b[1;32m    918\u001b[0m     #   While loader process is alive:\n\u001b[1;32m    919\u001b[0m     #     Get from `index_queue`.\n\u001b[1;32m    920\u001b[0m     #       If get anything else,\n\u001b[1;32m    921\u001b[0m     #          Check `workers_done_event`.\n\u001b[1;32m    922\u001b[0m     #            If set, continue to next iteration\n\u001b[1;32m    923\u001b[0m     #                    i.e., keep getting until see the `None`, then exit.\n\u001b[1;32m    924\u001b[0m     #            Otherwise, process data:\n\u001b[1;32m    925\u001b[0m     #                If is fetching from an `IterableDataset` and the iterator\n\u001b[1;32m    926\u001b[0m     #                    is exhausted, send an `_IterableDatasetStopIteration`\n\u001b[1;32m    927\u001b[0m     #                    object to signal iteration end. The main process, upon\n\u001b[1;32m    928\u001b[0m     #                    receiving such an object, will send `None` to this\n\u001b[1;32m    929\u001b[0m     #                    worker and not use the corresponding `index_queue`\n\u001b[1;32m    930\u001b[0m     #                    anymore.\n\u001b[1;32m    931\u001b[0m     #       If timed out,\n\u001b[1;32m    932\u001b[0m     #          No matter `workers_done_event` is set (still need to see `None`)\n\u001b[1;32m    933\u001b[0m     #          or not, must continue to next iteration.\n\u001b[1;32m    934\u001b[0m     #   (outside loop)\n\u001b[1;32m    935\u001b[0m     #   If `workers_done_event` is set,  (this can be False with `IterableDataset`)\n\u001b[1;32m    936\u001b[0m     #     `data_queue.cancel_join_thread()`.  (Everything is ending here:\n\u001b[1;32m    937\u001b[0m     #                                          main process won't read from it;\n\u001b[1;32m    938\u001b[0m     #                                          other workers will also call\n\u001b[1;32m    939\u001b[0m     #                                          `cancel_join_thread`.)\n\u001b[1;32m    940\u001b[0m     #\n\u001b[1;32m    941\u001b[0m     # [ pin_memory_thread ]\n\u001b[1;32m    942\u001b[0m     #   # No need to check main thread. If this thread is alive, the main loader\n\u001b[1;32m    943\u001b[0m     #   # thread must be alive, because this thread is set as daemonic.\n\u001b[1;32m    944\u001b[0m     #   While `pin_memory_thread_done_event` is not set:\n\u001b[1;32m    945\u001b[0m     #     Get from `worker_result_queue`.\n\u001b[1;32m    946\u001b[0m     #       If timed out, continue to get in the next iteration.\n\u001b[1;32m    947\u001b[0m     #       Otherwise, process data.\n\u001b[1;32m    948\u001b[0m     #       While `pin_memory_thread_done_event` is not set:\n\u001b[1;32m    949\u001b[0m     #         Put processed data to `data_queue` (a `queue.Queue` with blocking put)\n\u001b[1;32m    950\u001b[0m     #         If timed out, continue to put in the next iteration.\n\u001b[1;32m    951\u001b[0m     #         Otherwise, break, i.e., continuing to the out loop.\n\u001b[1;32m    952\u001b[0m     #\n\u001b[1;32m    953\u001b[0m     #   NOTE: we don't check the status of the main thread because\n\u001b[1;32m    954\u001b[0m     #           1. if the process is killed by fatal signal, `pin_memory_thread`\n\u001b[1;32m    955\u001b[0m     #              ends.\n\u001b[1;32m    956\u001b[0m     #           2. in other cases, either the cleaning-up in __del__ or the\n\u001b[1;32m    957\u001b[0m     #              automatic exit of daemonic thread will take care of it.\n\u001b[1;32m    958\u001b[0m     #              This won't busy-wait either because `.get(timeout)` does not\n\u001b[1;32m    959\u001b[0m     #              busy-wait.\n\u001b[1;32m    960\u001b[0m     #\n\u001b[1;32m    961\u001b[0m     # [ main process ]\n\u001b[1;32m    962\u001b[0m     #   In the DataLoader Iter's `__del__`\n\u001b[1;32m    963\u001b[0m     #     b. Exit `pin_memory_thread`\n\u001b[1;32m    964\u001b[0m     #          i.   Set `pin_memory_thread_done_event`.\n\u001b[1;32m    965\u001b[0m     #          ii   Put `None` in `worker_result_queue`.\n\u001b[1;32m    966\u001b[0m     #          iii. Join the `pin_memory_thread`.\n\u001b[1;32m    967\u001b[0m     #          iv.  `worker_result_queue.cancel_join_thread()`.\n\u001b[1;32m    968\u001b[0m     #\n\u001b[1;32m    969\u001b[0m     #     c. Exit the workers.\n\u001b[1;32m    970\u001b[0m     #          i.   Set `workers_done_event`.\n\u001b[1;32m    971\u001b[0m     #          ii.  Put `None` in each worker's `index_queue`.\n\u001b[1;32m    972\u001b[0m     #          iii. Join the workers.\n\u001b[1;32m    973\u001b[0m     #          iv.  Call `.cancel_join_thread()` on each worker's `index_queue`.\n\u001b[1;32m    974\u001b[0m     #\n\u001b[1;32m    975\u001b[0m     #        NOTE: (c) is better placed after (b) because it may leave corrupted\n\u001b[1;32m    976\u001b[0m     #              data in `worker_result_queue`, which `pin_memory_thread`\n\u001b[1;32m    977\u001b[0m     #              reads from, in which case the `pin_memory_thread` can only\n\u001b[1;32m    978\u001b[0m     #              happen at timing out, which is slow. Nonetheless, same thing\n\u001b[1;32m    979\u001b[0m     #              happens if a worker is killed by signal at unfortunate times,\n\u001b[1;32m    980\u001b[0m     #              but in other cases, we are better off having a non-corrupted\n\u001b[1;32m    981\u001b[0m     #              `worker_result_queue` for `pin_memory_thread`.\n\u001b[1;32m    982\u001b[0m     #\n\u001b[1;32m    983\u001b[0m     #   NOTE: If `pin_memory=False`, there is no `pin_memory_thread` and (b)\n\u001b[1;32m    984\u001b[0m     #         can be omitted\n\u001b[1;32m    985\u001b[0m     #\n\u001b[1;32m    986\u001b[0m     # NB: `done_event`s isn't strictly needed. E.g., we can just check for\n\u001b[1;32m    987\u001b[0m     #     `None` from `index_queue`, but it allows us to skip wasting resources\n\u001b[1;32m    988\u001b[0m     #     processing indices already in `index_queue` if we are already shutting\n\u001b[1;32m    989\u001b[0m     #     down.\n\u001b[1;32m    991\u001b[0m     def __init__(self, loader):\n\u001b[1;32m    992\u001b[0m         super().__init__(loader)\n",
      "File \u001b[0;32m~/.conda/envs/torch_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/torch_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,i):\n\u001b[0;32m---> 14\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43mload_signal_folder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_signals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_spectrograms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_spectrograms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     ret \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoice\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmix\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[6], line 26\u001b[0m, in \u001b[0;36mload_signal_folder\u001b[0;34m(folder, load_signals, load_spectrograms)\u001b[0m\n\u001b[1;32m     22\u001b[0m         res[key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m signal\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m f\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m SAVE_SPECTROGRAMS \u001b[38;5;129;01mand\u001b[39;00m load_spectrograms: \n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m# when SAVE_SPECTROGRAMS is False, we shouldn't be able to load them \u001b[39;00m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;66;03m# to save time, otherwise it's cheating.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m         res[key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspectrogram\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Create missing spectrograms\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_spectrograms:\n",
      "File \u001b[0;32m~/.conda/envs/torch_env/lib/python3.10/site-packages/torch/serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/.conda/envs/torch_env/lib/python3.10/site-packages/torch/serialization.py:1047\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;66;03m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m data_file \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(zip_file\u001b[38;5;241m.\u001b[39mget_record(pickle_file))\n\u001b[0;32m-> 1047\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m \u001b[43mUnpicklerWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m   1049\u001b[0m result \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'weights_only' is an invalid keyword argument for Unpickler()"
     ]
    }
   ],
   "source": [
    "train_dataset = MyDataset(train_folder,load_signals=True,load_spectrograms=True)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "print(\"Dataset length:\",len(train_dataset))\n",
    "for voice_signal,voice_spec,noise_signal,noise_spec,mix_signal,mix_spec,snr in train_dataloader:\n",
    "    print(\"Signal's shape: \",voice_signal.shape)\n",
    "    print(\"Spectrogram's shape: \",voice_spec.shape)\n",
    "    print(\"SNRs :\",snr)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq using a U-Net: Singing Voice Separation With Deep U-Net Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(\n",
    "    train_folder,\n",
    "    load_signals=False,\n",
    "    load_spectrograms=True)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spec's shape: torch.Size([32, 257, 268])\n",
      "SNRs: ('0', '0', '-2', '3', '0', '0', '-2', '4', '0', '3', '2', '-3', '-1', '1', '1', '-2', '0', '2', '1', '2', '0', '-3', '2', '2', '2', '0', '-2', '-2', '4', '-1', '-2', '-2')\n"
     ]
    }
   ],
   "source": [
    "for voice_spec,noise_spec,mix_spec,snr in train_dataloader:\n",
    "    print(\"Spec's shape:\",voice_spec.shape)\n",
    "    print(\"SNRs:\",snr)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
