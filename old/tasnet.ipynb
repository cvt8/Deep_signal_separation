{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "#matplotlib ipympl\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.axes._axes import Axes\n",
    "\n",
    "from IPython.display import Audio\n",
    "# Audio(data=signal.T,rate=fe)\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import stft,istft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=6><b>Meta paramètres</b></font>\n",
    "\n",
    "Comme calculer les spectrogrammes prend du temps, nous pouvons les calculer une fois pour toute puis les sauvegarder sur le disque. Toutefois, <font color=\"red\"><b>ceci triple l'espace occupé sur disque</b></font>: passant de 6.3 Go à 17.2 Go. Veuillez donc préciser le paramètre `SAVE_SPECTROGRAMS` selon si vous pouvez utiliser cet espace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = Path(\"source_separation\")\n",
    "SAVE_SPECTROGRAMS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des signaux, Visualisation et Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des signaux et spectrogrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = DIRECTORY / \"train\"\n",
    "train_small_folder = DIRECTORY / \"train_small\"\n",
    "test_folder = DIRECTORY / \"test\"\n",
    "get_path = lambda folder,i : folder / (\"000\"+str(i))[-4:]\n",
    "\n",
    "datasets_sizes = {\n",
    "    train_small_folder : 50,\n",
    "    train_folder : 5000,\n",
    "    test_folder : 2000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les signaux ont la même fréquence d'échantillonage, même longueur; et donc les mêmes f et t échantillonés pour le Spectrogramme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all_same(folder=train_small_folder):\n",
    "    f_ref = None\n",
    "    t_ref = None\n",
    "    for i in range(datasets_sizes[train_small_folder]):\n",
    "        fe,signal = wavfile.read(get_path(train_small_folder,i) / \"voice.wav\")\n",
    "        len_signal = len(signal)\n",
    "        f_spec,t_spec,spec = stft(\n",
    "            signal,fs=fe,\n",
    "            nperseg=400,nfft=512,noverlap=100)\n",
    "        if f_ref is None: f_ref = f_spec ; t_ref = t_spec\n",
    "        assert np.allclose(f_spec,f_ref)\n",
    "        assert np.allclose(t_spec,t_ref)\n",
    "    return fe,f_ref,t_ref\n",
    "\n",
    "fe,f_ref,t_ref = check_all_same()\n",
    "get_spectrogram = lambda signal : stft(signal,fs=fe,nperseg=400,nfft=512,noverlap=100)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_signal_folder(folder: Path,\n",
    "        load_signals=True,\n",
    "        load_spectrograms=True) -> dict[str,dict]:\n",
    "    \"\"\"\n",
    "    Return a dictionary with 3 sub dicts: \"voice\", \"noise\" and \"mix\"; and an \"SNR\" key.\n",
    "    Each sub dict has 3 keys: \"filename\", \"signal\" and \"spectrogram\" \n",
    "    (except if load_signals or load_spectrograms are set to False)\n",
    "    \"\"\"\n",
    "    keys = [\"voice\",\"noise\",\"mix\"]\n",
    "    res = dict((k,dict()) for k in keys)\n",
    "    for f in folder.iterdir():\n",
    "        assert f.is_file()\n",
    "        if \"voice\" in f.name: key = \"voice\"\n",
    "        elif \"noise\" in f.name: key = \"noise\"\n",
    "        else: \n",
    "            key = \"mix\"\n",
    "            if f.suffix == \".wav\":\n",
    "                res[\"SNR\"] = f.name.removesuffix(\".wav\").split(\"_\")[-1]\n",
    "        if f.suffix == \".wav\" and load_signals:\n",
    "            fe,signal = wavfile.read(f)\n",
    "            res[key][\"filename\"] = f.name\n",
    "            res[key][\"signal\"] = signal\n",
    "        elif f.suffix == \".pt\" and SAVE_SPECTROGRAMS and load_spectrograms: \n",
    "            # when SAVE_SPECTROGRAMS is False, we shouldn't be able to load them \n",
    "            # to save time, otherwise it's cheating.\n",
    "            res[key][\"spectrogram\"] = torch.load(f,weights_only=True)\n",
    "    # Create missing spectrograms\n",
    "    if load_spectrograms:\n",
    "        for key in keys:\n",
    "            if \"spectrogram\" not in res[key]:\n",
    "                assert load_signals\n",
    "                spec = get_spectrogram(res[key][\"signal\"])\n",
    "                res[key][\"spectrogram\"] = spec\n",
    "                if SAVE_SPECTROGRAMS:\n",
    "                    torch.save(torch.tensor(spec),folder / f\"{key}_spectrogram.pt\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def remove_all_spectrograms():\n",
    "    for folder in [train_folder,train_small_folder,test_folder]:\n",
    "        for i in range(datasets_sizes[folder]):\n",
    "            folder_i: Path = get_path(folder,i)\n",
    "            for f in folder_i.iterdir():\n",
    "                if \"spectrogram\" in f.name:\n",
    "                    f.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme calculer les spectrogrammes prend du temps, nous pouvons les calculer une fois pour toute, en sauvegardant tous les spectrogrammes sur disque. Attention, <font color=\"red\"><b>ceci triple l'espace occupé sur disque</b></font>: passant de 6.3 Go à 17.2 Go.\n",
    "Pour les retirer utiliser: `remove_all_spectrograms()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrograms(folder: Path):\n",
    "    if SAVE_SPECTROGRAMS and not (folder/\"0000\"/\"voice_spectrogram.pt\").exists():\n",
    "        for i in range(datasets_sizes[folder]):\n",
    "            load_signal_folder(get_path(folder,i))\n",
    "\n",
    "create_spectrograms(train_small_folder)\n",
    "create_spectrograms(test_folder)\n",
    "create_spectrograms(train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Première fois:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps total pour load 2000 signaux: 0.3951813392341137\n",
      "Temps total pour en calculer les spectrogrammes: 5.129137184470892\n",
      "Comparé au temps pour charger les spectrogrammes: 1.4271452724933624\n",
      "\n",
      "Deuxième fois:\n",
      "Temps total pour load 2000 signaux: 0.3989947997033596\n",
      "Temps total pour en calculer les spectrogrammes: 5.186291877180338\n",
      "Comparé au temps pour charger les spectrogrammes: 1.443577516824007\n"
     ]
    }
   ],
   "source": [
    "def compute_time(folder):\n",
    "    time_load_signal = 0\n",
    "    time_load_spec = 0\n",
    "    time_spec = 0\n",
    "    start = time.perf_counter()\n",
    "    for i in range(datasets_sizes[folder]):\n",
    "        fe,signal = wavfile.read(get_path(folder,i) / \"voice.wav\")\n",
    "        time_load_signal += time.perf_counter() - start ; start = time.perf_counter()\n",
    "        path_spec: Path = get_path(folder,i) / \"voice_spectrogram.pt\"\n",
    "        if path_spec.exists():\n",
    "            _ = torch.load(path_spec,weights_only=True)\n",
    "        time_load_spec += time.perf_counter() - start ; start = time.perf_counter()\n",
    "        _ = get_spectrogram(signal)\n",
    "        time_spec += time.perf_counter() - start ; start = time.perf_counter()\n",
    "\n",
    "    print(f\"Temps total pour load {datasets_sizes[folder]} signaux: {time_load_signal}\")\n",
    "    print(f\"Temps total pour en calculer les spectrogrammes: {time_spec}\")\n",
    "    print(f\"Comparé au temps pour charger les spectrogrammes: {time_load_spec}\")\n",
    "\n",
    "print(\"Première fois:\")\n",
    "compute_time(test_folder)\n",
    "print(\"\\nDeuxième fois:\")\n",
    "compute_time(test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que charger les spectrogrammes pré-calculés est plus rapide que de les calculer à chaque fois. On note aussi une grosse différence entre la première fois qu'un fichier est chargé et la seconde. Nous pensons que le système place les derniers fichiers chargés dans le cache (recharger le notebook n'y change rien, donc la différence n'apparait que la toute première fois)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "            folder: Path,\n",
    "            load_signals=True,\n",
    "            load_spectrograms=False):\n",
    "        self.folder = folder\n",
    "        self.load_signals = load_signals\n",
    "        self.load_spectrograms = load_spectrograms\n",
    "            \n",
    "    def __len__(self):\n",
    "        return datasets_sizes[self.folder]\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        d = load_signal_folder(\n",
    "            get_path(self.folder,i),\n",
    "            load_signals=self.load_signals,\n",
    "            load_spectrograms=self.load_spectrograms)\n",
    "        ret = []\n",
    "        for name in [\"voice\",\"noise\",\"mix\"]:\n",
    "            if self.load_signals:\n",
    "                ret.append(d[name][\"signal\"])\n",
    "            if self.load_spectrograms:\n",
    "                ret.append(d[name][\"spectrogram\"])\n",
    "        ret.append(d[\"SNR\"])\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Dataset peut contenir les signaux et/ou les spectrogrammes. De sorte à ne charger que le nécessaire. Exemple si on veut tout charger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 5000\n",
      "Signal's shape:  torch.Size([32, 80000])\n",
      "Spectrogram's shape:  torch.Size([32, 257, 268])\n",
      "SNRs : ('0', '0', '4', '-4', '0', '-3', '-2', '3', '-3', '-4', '0', '1', '-2', '-1', '2', '3', '-1', '0', '0', '-4', '3', '4', '-4', '-2', '2', '-1', '2', '1', '-4', '-1', '4', '0')\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MyDataset(train_folder,load_signals=True,load_spectrograms=True)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "print(\"Dataset length:\",len(train_dataset))\n",
    "for voice_signal,voice_spec,noise_signal,noise_spec,mix_signal,mix_spec,snr in train_dataloader:\n",
    "    print(\"Signal's shape: \",voice_signal.shape)\n",
    "    print(\"Spectrogram's shape: \",voice_spec.shape)\n",
    "    print(\"SNRs :\",snr)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Domain Audio Separation Network for Real-Time, Single-Channel Speech Separation\n",
    "(Inspired from Luo et al., 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(\n",
    "    train_folder,\n",
    "    load_signals=False,\n",
    "    load_spectrograms=True)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spec's shape: torch.Size([32, 257, 268])\n",
      "SNRs: ('-3', '3', '3', '0', '2', '1', '-3', '2', '-1', '-4', '1', '0', '-3', '0', '-3', '0', '-4', '-4', '-3', '-4', '-3', '0', '4', '-1', '1', '4', '-1', '0', '4', '3', '1', '2')\n"
     ]
    }
   ],
   "source": [
    "for voice_spec,noise_spec,mix_spec,snr in train_dataloader:\n",
    "    print(\"Spec's shape:\",voice_spec.shape)\n",
    "    print(\"SNRs:\",snr)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
